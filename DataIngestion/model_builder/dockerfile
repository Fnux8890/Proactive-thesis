FROM rapidsai/base:25.04-cuda12.8-py3.12

# Add conda paths to PATH explicitly
ENV PATH=/opt/conda/bin:/opt/conda/condabin:${PATH}

# Set CUDA environment variables
ENV CUDA_HOME=/usr/local/cuda
ENV PATH=${CUDA_HOME}/bin:${PATH}
ENV LD_LIBRARY_PATH=${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}

# Install build tools for LightGBM GPU support using conda/mamba
RUN mamba install -y -c conda-forge \
    cmake \
    make \
    boost \
    boost-cpp \
    compilers \
    git \
    && mamba clean -afy

# Install Python packages
RUN pip install --no-cache-dir uv \
    && uv pip install --system --no-cache-dir \
    torch==2.3.* pytorch-lightning==2.* \
    pandas==2.* pyarrow==15.* \
    scikit-learn==1.* matplotlib==3.* seaborn==0.13.* \
    typing-extensions joblib==1.4.* \
    mlflow-skinny \
    sqlalchemy==2.* psycopg2-binary

# Install LightGBM
# Note: RAPIDS base image includes cuML which has GPU-accelerated algorithms
# For now, use standard LightGBM and rely on RAPIDS for GPU acceleration
RUN pip install --no-cache-dir lightgbm==4.*

# Create a writable /tmp/mlflow directory for potential client-side staging
RUN mkdir -p /tmp/mlflow && chmod 777 /tmp/mlflow

ENV PYTHONUNBUFFERED=1
ENV CUDA_LAUNCH_BLOCKING=1
ENV NVIDIA_VISIBLE_DEVICES=all
ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility

WORKDIR /app
COPY src/ ./src/
COPY pyproject.toml ./

# Default to training all objectives
CMD ["python", "-m", "src.training.train_all_objectives"]
