# MOEA Optimizer

Multi-Objective Evolutionary Algorithm (MOEA) benchmarking framework for comparing CPU and GPU implementations.

## Implementation Status

### âœ… Completed

#### Epic 1: Environment & CI/CD
- [x] Created `pyproject.toml` with pinned dependencies
- [x] Poetry configuration for reproducible installs
- [x] Project structure following the software plan

#### Epic 2: CPU Baseline (pymoo)
- [x] NSGA-III wrapper implementation (`nsga3_pymoo.py`)
- [x] Configuration loading from YAML files
- [x] Progress logging and callbacks
- [x] Results serialization (numpy arrays, CSV metrics)

#### Epic 3: Core Infrastructure
- [x] Configuration loader with YAML inheritance
- [x] Random seed management for reproducibility
- [x] Timer utilities with CUDA synchronization support
- [x] CLI interface with Click

#### Epic 5: Evaluation & Stats
- [x] Performance metrics (HV, IGD+, epsilon, spacing)
- [x] Convergence tracking
- [x] Results aggregation across multiple runs

### ðŸš§ In Progress

#### Epic 3: GPU Tensor (EvoX)
- [ ] TensorNSGA-III implementation wrapper
- [ ] Batch evaluation on GPU
- [ ] Memory monitoring

#### Epic 4: Benchmark Suite
- [x] DTLZ wrapper for pymoo
- [ ] WFG suite wrapper
- [ ] Real-world problem interfaces

### ðŸ“‹ TODO

#### Epic 6: Automation & Reporting
- [ ] Visualization module (convergence plots, Pareto fronts)
- [ ] Statistical comparison (Wilcoxon, A12 effect size)
- [ ] HTML report generation
- [ ] GitHub Actions workflow

## Installation

```bash
# Install Poetry if not already installed
curl -sSL https://install.python-poetry.org | python3 -

# Install dependencies
poetry install

# Install with GPU support
poetry install -E gpu
```

## Usage

### Running Experiments

```bash
# Run CPU benchmark
poetry run moea-optimizer run --config config/cpu_dtlz.yaml

# Run GPU benchmark (when implemented)
poetry run moea-optimizer run --config config/gpu_dtlz.yaml

# Generate custom configuration
poetry run moea-optimizer generate-config \
  --base config/base.yaml \
  --output config/custom.yaml \
  --device gpu \
  --problem dtlz
```

### CLI Commands

```bash
# List available test problems
poetry run moea-optimizer list-problems

# Generate report from results
poetry run moea-optimizer report --results results/cpu_dtlz

# Run with debug logging
poetry run moea-optimizer --debug run --config config/cpu_dtlz.yaml
```

## Configuration

Configuration files use YAML format with inheritance from `base.yaml`:

```yaml
# config/base.yaml
seeds:
  numpy: 42
  torch: 42
  replications: 5

algorithm:
  population_size: 100
  n_generations: 200
  
# config/cpu_dtlz.yaml (inherits from base.yaml)
hardware:
  device: "cpu"
  
problem:
  suite: "dtlz"
  problems:
    - name: "DTLZ1"
      n_var: 7
      n_obj: 3
```

## Project Structure

```
moea_optimizer/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ base.yaml           # Base configuration
â”‚   â”œâ”€â”€ cpu_dtlz.yaml      # CPU DTLZ benchmark
â”‚   â””â”€â”€ gpu_dtlz.yaml      # GPU DTLZ benchmark
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ algorithms/
â”‚   â”‚   â”œâ”€â”€ cpu/
â”‚   â”‚   â”‚   â””â”€â”€ nsga3_pymoo.py
â”‚   â”‚   â””â”€â”€ gpu/
â”‚   â”‚       â””â”€â”€ nsga3_tensor.py (TODO)
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config_loader.py
â”‚   â”‚   â”œâ”€â”€ optimizer_runner.py
â”‚   â”‚   â””â”€â”€ evaluation.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ seed.py
â”‚   â”‚   â””â”€â”€ timer.py
â”‚   â””â”€â”€ cli.py
â”œâ”€â”€ tests/
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

## Results Format

Results are saved in the following structure:

```
results/
â””â”€â”€ experiment_name/
    â”œâ”€â”€ config.yaml           # Configuration used
    â”œâ”€â”€ summary.csv          # Aggregated metrics
    â”œâ”€â”€ complete_results.json # Detailed results
    â”œâ”€â”€ report.md            # Markdown report
    â””â”€â”€ problem_name/
        â””â”€â”€ run_0/
            â”œâ”€â”€ pareto_F.npy     # Objective values
            â”œâ”€â”€ pareto_X.npy     # Decision variables
            â”œâ”€â”€ metrics.json     # Performance metrics
            â””â”€â”€ convergence.csv  # Convergence history
```

## Development

### Running Tests

```bash
# Run all tests
poetry run pytest

# Run with coverage
poetry run pytest --cov=src --cov-report=html

# Run specific test
poetry run pytest tests/test_evaluation.py
```

### Code Quality

```bash
# Format code
poetry run black src/

# Sort imports
poetry run isort src/

# Lint code
poetry run flake8 src/

# Type checking
poetry run mypy src/
```

## Next Steps

1. **Implement GPU wrapper**: Create `nsga3_tensor.py` using EvoX
2. **Add visualization**: Implement plotting functions in `visualiser.py`
3. **Statistical tests**: Add Wilcoxon and effect size calculations
4. **CI/CD**: Set up GitHub Actions workflow
5. **Docker support**: Add GPU-enabled Dockerfile

## Contributing

1. Follow the established code structure
2. Add tests for new functionality
3. Update documentation
4. Run code quality checks before committing

## License

[Your license here]