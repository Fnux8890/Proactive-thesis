services:
  # web_service: # Keep commented out unless needed later
  #   build:
  #     context: ./web_service # Adjust context if web service is elsewhere
  #     dockerfile: Dockerfile.web
  #   restart: always
  #   ports:
  #     - "4000:4000"
  #   depends_on:
  #     - redis
  #   environment:
  #     - PYTHONUNBUFFERED=1 # Often useful for Python logging in Docker
  #     - PORT=4000
  #     - REDIS_URL=redis://redis:6379
  #     # Add other necessary env vars
  #   healthcheck:
  #     test: ["CMD", "wget", "-qO-", "http://localhost:4000/health"] # Adjust healthcheck endpoint
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 5s
  #   volumes:
  #     - ./results:/app/results # Map results volume
  #     - ../../Data:/app/data:ro # Map data volume (read-only if pipeline only reads)
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 512M
  #         cpus: '0.5'
  #   networks:
  #     - ingestion-net

  python_pipeline:
    build:
      context: . # Build context is the current directory (python_pipeline)
      dockerfile: Dockerfile # Use the Dockerfile created earlier
    volumes:
      # Mount a directory for cleaned data output if saving to files
      - ./cleaned_data:/app/cleaned_data
      # Mount the source data directory (read-only recommended)
      - ../../Data:/app/data:ro
      # You might need a results volume if the script produces other outputs
      # - ./results:/app/results
    depends_on:
      - redis # If the pipeline needs to interact with Redis
      - db # If the pipeline needs to interact with the DB
    environment:
      # Pass the path to the data inside the container
      DATA_SOURCE_PATH: /app/data
      # Pass the path for the output *inside* the container
      OUTPUT_DATA_PATH: /app/cleaned_data
      # Pass Redis URL if needed
      REDIS_URL: redis://redis:6379
      # Pass Database URL if needed (adjust user/pass/db name as needed)
      DATABASE_URL: postgresql://postgres:postgres@db:5432/postgres
      # Ensure Python logs appear immediately
      PYTHONUNBUFFERED: 1
      # Set the save format to database
      SAVE_FORMAT: "db"
    deploy:
      resources:
        limits:
          memory: 2G # Adjust memory based on expected data size
          cpus: '1.0' # Adjust CPU based on processing needs
    networks:
      - ingestion-net

  rust_pipeline:
    build:
      context: ../rust_pipeline # Corrected relative path
      dockerfile: Dockerfile
    volumes:
      # Mount the source data directory (read-only)
      - ../Data:/app/data:ro
      # Potentially mount results or cleaned_data later
    depends_on:
      - redis # If needed later
      - db # If needed later
    environment:
      # Pass the path to the data inside the container
      DATA_SOURCE_PATH: /app/data
      # Pass Redis URL if needed
      REDIS_URL: redis://redis:6379
      # Pass Database URL if needed
      DATABASE_URL: postgresql://postgres:postgres@db:5432/postgres
    deploy:
      resources:
        limits:
          memory: 1G # Start with less memory than Python for now
          cpus: '0.5'
    networks:
      - ingestion-net

  redis:
    image: redis:alpine
    restart: always
    ports:
      - "6379:6379"
    command: redis-server --save 60 1 --loglevel warning
    volumes:
      - redis-data:/data
    networks:
      - ingestion-net

  db:
    # Use the official TimescaleDB image with PostgreSQL 16
    image: timescale/timescaledb:latest-pg16
    restart: always
    environment:
      # Standard PostgreSQL environment variables are used
      POSTGRES_USER: "postgres"
      POSTGRES_PASSWORD: "postgres" # Use a strong password in production!
      # POSTGRES_DB: sensor_data # Optional: Define a specific database name on init
      # TIMESCALEDB_TELEMETRY: off # Optional: Disable TimescaleDB telemetry
    volumes:
      # Persist data using a named volume mapped to the standard PGDATA location
      - postgres-data:/var/lib/postgresql/data
    ports:
      # Keep the standard port mapping
      - "5432:5432"
    networks:
      - ingestion-net

  pgadmin:
    image: dpage/pgadmin4:latest
    restart: always
    environment:
      PGADMIN_DEFAULT_EMAIL: "admin@example.com" # Change this!
      PGADMIN_DEFAULT_PASSWORD: "admin" # Change this!
      PGADMIN_CONFIG_SERVER_MODE: "False" # Run in Desktop mode
    volumes:
      - pgadmin-data:/var/lib/pgadmin
    ports:
      - "5050:80" # Map host port 5050 to container port 80
    depends_on:
      - db
    networks:
      - ingestion-net
  # elixir_pipeline: # Keep the Elixir definition commented out for reference
  #   build:
  #     context: ../elixir_ingestion/pipeline # Adjust path relative to this docker-compose file if needed
  #     dockerfile: Dockerfile.pipeline
  #   volumes:
  #     - ../elixir_ingestion/results:/app/results # Adjust path
  #     - ../../Data:/app/data:ro
  #   depends_on:
  #     - redis
  #     - db
  #   environment:
  #     DATA_SOURCE_PATH: /app/data
  #     REDIS_URL: redis://redis:6379
  #     MIX_ENV: dev
  #     PIPELINE_WATCH_DIR: /app/data
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 2G
  #         cpus: '2.0'
  #   networks:
  #     - ingestion-net

volumes:
  postgres-data: # Define the named volume for PostgreSQL
  redis-data: # Define the named volume for Redis
  pgadmin-data:
    # Define the named volume for pgAdmin

networks:
  ingestion-net:
    name: ingestion-net
    driver: bridge # Use bridge driver for single-host networking 
