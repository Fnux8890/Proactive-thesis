# Cloud/Production Override for Google Cloud A2 Instance
# Use with: docker compose -f docker-compose.yml -f docker-compose.cloud.yml up

services:
  # Database - optimized for production
  db:
    environment:
      - POSTGRES_SHARED_BUFFERS=8GB  # 25% of available RAM
      - POSTGRES_EFFECTIVE_CACHE_SIZE=24GB  # 75% of RAM
      - POSTGRES_WORK_MEM=256MB
      - POSTGRES_MAINTENANCE_WORK_MEM=2GB
      - POSTGRES_MAX_CONNECTIONS=500
      - POSTGRES_MAX_PARALLEL_WORKERS=24
    deploy:
      resources:
        limits:
          cpus: '8'
          memory: 32G
    restart: always

  # Redis for parallel coordination
  redis:
    image: redis:7-alpine
    command: redis-server --maxmemory 8gb --maxmemory-policy allkeys-lru
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 8G
    restart: always

  # PgBouncer for connection pooling
  pgbouncer:
    image: pgbouncer/pgbouncer:latest
    environment:
      - DATABASES_HOST=db
      - DATABASES_PORT=5432
      - DATABASES_DATABASE=postgres
      - DATABASES_USER=postgres
      - DATABASES_PASSWORD=postgres
      - POOL_MODE=transaction
      - MAX_CLIENT_CONN=1000
      - DEFAULT_POOL_SIZE=50
    depends_on:
      - db
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
    restart: always

  # Preprocessing - comprehensive features for production
  preprocessing:
    environment:
      - LOG_LEVEL=INFO
      - FEATURE_SET=comprehensive  # All features for production
      - BATCH_SIZE=10000  # Larger batches for efficiency
      - N_WORKERS=8
    deploy:
      resources:
        limits:
          cpus: '8'
          memory: 16G
    restart: on-failure

  # Era Detection - optimized buffers
  era_detector:
    environment:
      - RUST_LOG=info
      - CHANNEL_BUFFER_SIZE=10000
      - BATCH_SIZE=5000
      - RAYON_NUM_THREADS=16
    deploy:
      resources:
        limits:
          cpus: '16'
          memory: 32G
    restart: on-failure

  # Parallel Feature Extraction Coordinator
  feature-coordinator:
    build:
      context: ./feature_extraction
      dockerfile: parallel/coordinator.dockerfile
    environment:
      - REDIS_URL=redis://redis:6379
      - DATABASE_URL=postgresql://postgres:postgres@pgbouncer:6432/postgres
      - GPU_WORKERS=4
      - CPU_WORKERS=8
      - GPU_THRESHOLD=500000
      - USE_SMART_DISTRIBUTION=true
      - FEATURE_SET=comprehensive
    depends_on:
      - redis
      - pgbouncer
      - preprocessing
      - era_detector
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 8G

  # GPU Feature Workers (4 containers)
  feature-gpu-worker-0:
    build:
      context: ./feature_extraction
      dockerfile: parallel/gpu_worker.dockerfile
    environment:
      - WORKER_ID=gpu-0
      - CUDA_VISIBLE_DEVICES=0
      - REDIS_URL=redis://redis:6379
      - DATABASE_URL=postgresql://postgres:postgres@pgbouncer:6432/postgres
      - FEATURE_SET=comprehensive
    runtime: nvidia
    depends_on:
      - feature-coordinator
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
        limits:
          cpus: '5'
          memory: 40G
    restart: on-failure

  feature-gpu-worker-1:
    extends: feature-gpu-worker-0
    environment:
      - WORKER_ID=gpu-1
      - CUDA_VISIBLE_DEVICES=1
      - REDIS_URL=redis://redis:6379
      - DATABASE_URL=postgresql://postgres:postgres@pgbouncer:6432/postgres
      - FEATURE_SET=comprehensive
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['1']
              capabilities: [gpu]
        limits:
          cpus: '5'
          memory: 40G

  feature-gpu-worker-2:
    extends: feature-gpu-worker-0
    environment:
      - WORKER_ID=gpu-2
      - CUDA_VISIBLE_DEVICES=2
      - REDIS_URL=redis://redis:6379
      - DATABASE_URL=postgresql://postgres:postgres@pgbouncer:6432/postgres
      - FEATURE_SET=comprehensive
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['2']
              capabilities: [gpu]
        limits:
          cpus: '5'
          memory: 40G

  feature-gpu-worker-3:
    extends: feature-gpu-worker-0
    environment:
      - WORKER_ID=gpu-3
      - CUDA_VISIBLE_DEVICES=3
      - REDIS_URL=redis://redis:6379
      - DATABASE_URL=postgresql://postgres:postgres@pgbouncer:6432/postgres
      - FEATURE_SET=comprehensive
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['3']
              capabilities: [gpu]
        limits:
          cpus: '5'
          memory: 40G

  # CPU Feature Workers (4 containers, reduced from 8 for better resource allocation)
  feature-cpu-worker:
    build:
      context: ./feature_extraction
      dockerfile: parallel/cpu_worker.dockerfile
    environment:
      - REDIS_URL=redis://redis:6379
      - DATABASE_URL=postgresql://postgres:postgres@pgbouncer:6432/postgres
      - TSFRESH_N_JOBS=4
      - FEATURE_SET=comprehensive
    depends_on:
      - feature-coordinator
    deploy:
      replicas: 4
      resources:
        limits:
          cpus: '4'
          memory: 20G
    restart: on-failure

  # Model Builder - GPU version
  model_builder:
    environment:
      - DEVICE=gpu
      - EPOCHS=100
      - BATCH_SIZE=256
      - LOG_LEVEL=INFO
      - N_GPUS=2  # Use 2 GPUs for model training
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 2
              capabilities: [gpu]
        limits:
          cpus: '8'
          memory: 64G
    restart: on-failure

  # MOEA Optimizer - GPU version
  moea_optimizer:
    build:
      context: ./moea_optimizer
      dockerfile: Dockerfile.gpu
    environment:
      - USE_GPU=true
      - N_GPUS=2
      - POPULATION_SIZE=500
      - GENERATIONS=200
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 2
              capabilities: [gpu]
        limits:
          cpus: '8'
          memory: 32G
    restart: on-failure

  # Monitoring Stack
  prometheus:
    image: prom/prometheus:latest
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
    restart: always

  grafana:
    image: grafana/grafana:latest
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/datasources:/etc/grafana/provisioning/datasources
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G
    restart: always

  # GPU monitoring
  dcgm-exporter:
    image: nvidia/dcgm-exporter:latest
    environment:
      - DCGM_EXPORTER_NO_HOSTNAME=1
    ports:
      - "9400:9400"
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
        limits:
          cpus: '0.5'
          memory: 1G
    restart: always

volumes:
  redis-data:
  prometheus-data:
  grafana-data: